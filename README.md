# üé§ Vocals - Speech Therapy Software App

**Empowering voices, one exercise at a time.**  
An open-source, accessible platform for speech therapy‚Äîdesigned to support individuals with speech disorders through guided exercises, real-time feedback, and progress tracking.

---

## üöÄ About the Project

Speech disorders can make communication challenging and impact confidence and quality of life. Unfortunately, access to traditional therapy is often limited by high costs, in-person requirements, and lack of availability in remote areas.

**Vocals** addresses these barriers by offering a digital, user-friendly alternative:
- üëÑ Guided speech exercises
- üéôÔ∏è Real-time pronunciation feedback
- üìä Progress tracking and insights
- üß† AI-assisted recommendations (coming soon)

Whether you're a speech therapy patient, practitioner, or just looking to improve articulation, Vocals offers an intuitive and empowering experience‚Äîaccessible anytime, anywhere.

---

## üõ†Ô∏è Tech Stack

This project is built using modern web technologies for speed, responsiveness, and ease of development:

- **React** ‚Äì for building dynamic user interfaces  
- **Tailwind CSS** ‚Äì for fast, utility-first styling  
- **Node.js + Express.js** ‚Äì for server-side logic and API handling  
- **Speech Recognition APIs** ‚Äì for real-time pronunciation feedback  

---

## üì¶ Getting Started

### Prerequisites

Ensure you have Node.js and npm installed. We recommend using [nvm](https://github.com/nvm-sh/nvm#installing-and-updating) for managing Node versions.

### Installation

```bash
# Clone the repository
git clone https://github.com/SauravSreejith/Vocals.git

# Navigate to the project directory
cd vocals-app

# Install dependencies
npm install

# Start the development server
npm run dev
```

The app should now be running at `http://localhost:5173`.

### Start the backend server

Ensure that you run the backend server service using the following command:
```
node backend/server.js
```

You also need to have an LLM Inference server in background running for the AI features. The currently selected model is llama3, which can be edited in `backend/server.js`.

We recommend using [Ollama](https://github.com/ollama/ollama) or [LM Studio](https://lmstudio.ai/docs/app/api). You may need to setup a JSON schema for proper parsing.


---

## üåê Deployment

To deploy this app on your preferred hosting service:

1. Build the app using:
   ```bash
   npm run build
   ```

2. Upload the `dist/` folder to services like **Netlify**, **Vercel**, or **GitHub Pages**.

---

## üí° Features in Progress

- üîí User login & personalized profiles  
- üß† AI-generated summaries and improvement tips  
- üè• Doctor recommendations based on user tags  
- üì± Mobile app version  

---

## üëê Contributing

We welcome community contributions to make Vocals even better!

1. Fork the repo
2. Create a new branch: `git checkout -b feature/your-feature-name`
3. Make your changes and commit: `git commit -m "Add your feature"`
4. Push to your fork: `git push origin feature/your-feature-name`
5. Open a pull request and describe your changes

---

## üìÑ License

This project is open-source under the [MIT License](LICENSE).

---

## üôå Acknowledgments

Thanks to the open-source community for tools, libraries, and support that make projects like this possible.

> Made with ‚ù§Ô∏è to help everyone speak freely and confidently.
